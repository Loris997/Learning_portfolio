{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5Z/syiQLkLYThuB5D+W16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loris997/Learning_portfolio/blob/main/Homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Theory part**"
      ],
      "metadata": {
        "id": "daTPlPprv9Hn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a pre-trained NLP model?**\n",
        "\n",
        "Pre-trained Natural Language Processing models are models, which have been trained with a large dataset. So it is not always needed to train a new model from scratch. It's much faster and cheaper to just load a pre-trained model and in case of need fine tune it."
      ],
      "metadata": {
        "id": "bEUAwH0eHBS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **How do I load them (NLP)?**\n",
        "\n",
        " Anyone can download a pre trained model.\n",
        "\n",
        "\n",
        "```\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "```\n",
        "\n",
        "In this example the pre-trained model distilgpt2 is loaded from the library transformers.\n"
      ],
      "metadata": {
        "id": "l4TR_sI4HG_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does fine-tuning mean?**\n",
        "\n",
        "Fine-tuning is the process of training a pre-trained NLP on a specific task. Therefore a smaller, sepcific dataset."
      ],
      "metadata": {
        "id": "9LW3MtjQHG5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is tokenization?**\n",
        "\n",
        "This is the process where a text is broken into smaller parts -> tokens. These tokens can be words or even characters. Especially for text classification or translation this process is used.\n",
        "\n",
        "When an input is tokanized, it is possible for the model to process the information and actually do work with it. Furthermore whitespaces are eliminated."
      ],
      "metadata": {
        "id": "tRwLGj-rHG8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What possibilities do I have with the Transformers package?**\n",
        "\n",
        "\n",
        "\n",
        "*   Question answering\n",
        "\n",
        "It's possible to answer questions on a given text.\n",
        "\n",
        "*   Zero-shot classification\n",
        "\n",
        "Can be used for texts which haven't been classified. Zero-shot-classification allows to specifiy which labels should be usedfor the classification. Therefore it is possible to classify texts with other labels than in the pre trained model.\n",
        "\n",
        "*   Text generation\n",
        "\n",
        "It's possible to generate texts or autocomplete sentences.\n",
        "\n",
        "*   Mask filling\n",
        "\n",
        "If there is a text with blanks, it is possible to fill these holes.\n",
        "\n",
        "*   Summarization\n",
        "\n",
        "It's possible to summarize texts. A max_lenght or min_lenght can be defined.\n",
        "\n",
        "*   Translation\n",
        "\n",
        " It's possible to translate translate texts.\n",
        "\n"
      ],
      "metadata": {
        "id": "2ioyd6NcHG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What types of NLP Models are there?**\n",
        "\n",
        "\n",
        "*   Language modeling models\n",
        "\n",
        "Finish started sentences.\n",
        "\n",
        "*   Text classification models\n",
        "\n",
        "Classify texts into categories.\n",
        "\n",
        "*   Named entity recognition models\n",
        "\n",
        "Identify and classify named entities in texts(Peoples, Cities, places..).\n",
        "\n",
        "*   Text generation models\n",
        "\n",
        "Create texts\n",
        "\n",
        "*   Question answering models\n",
        "\n",
        "Answer questions based on a text.\n"
      ],
      "metadata": {
        "id": "rQjOG_s-HGzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is an Encoder?**\n",
        "\n",
        "The encoder takes input tokens and transforms them into a fixed-lenght vector.\n",
        "The goal is to create a informative representation which then can then be further used. For example by the decoder."
      ],
      "metadata": {
        "id": "QNLhB7kWHGsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a Decoder?**\n",
        "\n",
        "The decoder takes the fixed lenght vector from the encoder and generates an output, for example a translated sentence."
      ],
      "metadata": {
        "id": "ujcNRViRHGYb"
      }
    }
  ]
}